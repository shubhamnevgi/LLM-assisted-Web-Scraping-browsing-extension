# Generative AI-based Web Scraping Browser Extension  

## ğŸ“Œ Project Overview  
 A Generative AI-powered Web Scraping Browser Extension using FastAPI, BeautifulSoup, Selenium, and Llama 3.3 with LangChain (Groq's model). It extracts and structures web data, allowing users to input URLs, scrape dynamic content, and download data in CSV, JSON, XML, and Excel formats with AI-based parsing and future scalability.

---

This project is a **Generative AI-powered Web Scraping Browser Extension** that enables users to extract data from websites efficiently. The extension allows users to input URLs, scrape web data dynamically, and format it into structured formats such as **CSV, JSON, XML, and Excel**. It integrates a **FastAPI backend** for handling scraping operations and AI-based data parsing.  

## ğŸš€ Features  
- **Web Scraping**: Extracts data from static and dynamic web pages using **BeautifulSoup** and **Selenium**.  
- **AI-Powered Parsing**: Utilizes **Llama 3.3 with LangChain (Groq's model)** for intelligent data processing and structuring.  
- **Multiple Data Formats**: Supports **CSV, JSON, XML, and Excel** downloads.  
- **Browser Extension Interface**: Allows users to input URLs, manage scraping settings, and download data in the preferred format.  
- **FastAPI Backend**: Ensures seamless communication between the extension and the AI-powered backend.  

## ğŸ“‚ Project Structure  
```
project/
â”œâ”€â”€ backend/                            # FastAPI Backend
â”‚   â”œâ”€â”€ app.py                          # Main FastAPI app
â”‚   â”œâ”€â”€ models.py                       # Data models and schemas
â”‚   â”œâ”€â”€ services/                       # Business logic like scraping, parsing
â”‚   â”‚   â”œâ”€â”€ __init__.py                 # Make the folder a Python package
â”‚   â”‚   â”œâ”€â”€ scrape.py                   # Web scraping logic
â”‚   â”‚   â””â”€â”€ parse.py                    # Parsing logic (AI-based, HuggingFace)
â”‚   â”œâ”€â”€ routers/                        # API routes (FastAPI routes)
â”‚   â”‚   â”œâ”€â”€ __init__.py                 # Make the folder a Python package
â”‚   â”‚   â”œâ”€â”€ main.py                     # Routes for scraping and parsing
â”‚   â”‚   â””â”€â”€ visualize.py                # Route for data visualization (if needed)
â”‚   â”œâ”€â”€ static/                         # Static files (graphs, temporary data files)
â”‚   â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ extension/                          # Browser Extension
â”‚   â”œâ”€â”€ manifest.json                   # Extension configuration (defines permissions, etc.)
â”‚   â”œâ”€â”€ popup.html                      # Popup UI for the extension
â”‚   â”œâ”€â”€ popup.js                        # JavaScript to interact with the backend (API requests)
â”‚   â””â”€â”€ styles.css                      # Styling for the extension's popup
â”œâ”€â”€ web_app/                            # Optional: Web application for data visualization
â”‚   â”œâ”€â”€ app.py                          # Main backend (FastAPI)
â”‚   â”œâ”€â”€ templates/                      # HTML templates for frontend
â”‚   â”œâ”€â”€ static/                         # Static files for the web app
â”‚   â”œâ”€â”€ requirements.txt                # Python dependencies
```

## ğŸ› ï¸ Technologies Used  
- **Backend**: Python, FastAPI, BeautifulSoup, Selenium, Llama 3.3 with LangChain (Groq's model)  
- **Browser Extension**: HTML, JavaScript (Manifest V3)  
- **Data Formats**: CSV, JSON, XML, Excel  

## ğŸ“Œ How to Get Started  

### 1ï¸âƒ£ Clone the Repository  
```bash
git clone https://github.com/yourusername/Generative-AI-based-Web-Scraping-browsing-extension.git
cd Generative-AI-based-Web-Scraping-browsing-extension
```

### 2ï¸âƒ£ Create a virtual environment  
Create a virtual environment:  
```bash
python -m venv venv
```
Activate this virtual environment:  
```bash
venv\Scripts\activate     # On Windows
source venv/bin/activate  # On Linux/Mac
```

### 3ï¸âƒ£ Setup Backend  
Install dependencies:  
```bash
pip install -r backend/requirements.txt
```

### 4ï¸âƒ£ Set up environment variables
Create a .env file in the root directory.
Add your Groq API key:
```bash
GROQ_API_KEY=your_groq_api_key_here
```

### 5ï¸âƒ£ Run FastAPI backend:  
```bash
<<<<<<< HEAD
uvicorn backend.app:app --reload
=======
uvicorn backend.main:app --reload
>>>>>>> 591b0eda9c46a1bfc7af3ef912a20ece51fe5fdf
```

### 6ï¸âƒ£ Load Browser Extension  
1. Open **Chrome** and go to `chrome://extensions/`.  
2. Enable **Developer Mode** (top right corner).  
3. Click **Load Unpacked** and select the `extension/` folder.  
4. The extension should now be active in your browser.  

---
